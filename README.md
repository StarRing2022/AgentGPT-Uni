# ChatUni-GLM
实现一种基于Chatglm6B预训练模型+LLAMA+Alpaca Lora的融合方案，该方案简单易行，目标是使此类语言模型实现低能耗广泛部署，并最终在小模型的基座上实现“智能涌现”


To Do
