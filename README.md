# ChatGLM-U
实现一种基于Chatglm6B预训练模型+LLAMA+Alpaca Lora的融合方案，该方案简单易行，目标是使此类语言模型实现低能耗广泛部署，并最终在小模型的基座上实现“智能涌现”


To Do
如您对我们的工作产生兴趣，请加入我们的QQ群号：731968085

真挚致谢：
ChatRWKV:https://github.com/BlinkDL/ChatRWKV
ChatGLM:ttps://github.com/THUDM/ChatGLM-6B 
